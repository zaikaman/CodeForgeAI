---
title: Models & Providers
description: Configure LLM models from Gemini, OpenAI, Anthropic, and other providers with ADK-TS agents
---

import { Cards, Card } from "fumadocs-ui/components/card";
import { Callout } from "fumadocs-ui/components/callout";
import { Tabs, Tab } from "fumadocs-ui/components/tabs";

ADK-TS provides flexible model integration, allowing you to use various Large Language Models (LLMs) with your agents. The framework defaults to Google Gemini models but supports extensive customization through two main approaches.

## Model Integration Options

ADK-TS supports two primary ways to configure models:

<Cards>
  <Card
    title="🎯 Option 1: Direct Model Names"
    description="Pass model names directly to agents - Gemini is default, others require environment configuration"
  />

  <Card
    title="🔌 Option 2: Vercel AI SDK"
    description="Use model instances from Vercel AI SDK for extensive provider support"
  />
</Cards>

## Option 1: Direct Model Names

The simplest approach - pass model names as strings directly to your agents. ADK-TS defaults to **Gemini models** but supports other providers when properly configured.

### Default: Google Gemini Models

**Gemini is the default provider**, but you still need to configure your API key:

**1. Set up your Google API key:**

```bash
# .env file
GOOGLE_API_KEY=your_google_api_key_here
```

**2. Use Gemini models directly:**

```ts
import { LlmAgent } from "@iqai/adk";

// Default Gemini models (just need GOOGLE_API_KEY in .env)
const agent = new LlmAgent({
  name: "my_agent",
  model: "gemini-2.0-flash-exp", // Fast and latest
  instruction: "You are a helpful assistant",
});

// Other Gemini models
const fastAgent = new LlmAgent({
  name: "fast_agent",
  model: "gemini-2.0-flash", // Fast and efficient
});

const powerfulAgent = new LlmAgent({
  name: "powerful_agent",
  model: "gemini-2.0-pro", // Complex reasoning
});
```

### Using Other Providers

To use **non-Gemini models**, you must configure your environment:

**1. Set the model name in your environment:**

```bash
# .env file
LLM_MODEL=gpt-4o  # or claude-3-5-sonnet-20241022, etc.
```

**2. Add the corresponding API key:**

```bash
# .env file
LLM_MODEL=gpt-4o
OPENAI_API_KEY=your_openai_api_key_here

# Or for Claude:
LLM_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Or for other providers:
LLM_MODEL=llama-3.1-70b-versatile
GROQ_API_KEY=your_groq_api_key_here
```

**3. Use the model name in your agent:**

```ts
import { LlmAgent } from "@iqai/adk";

const agent = new LlmAgent({
  name: "my_agent",
  model: "gpt-4o", // Must match your .env LLM_MODEL
  instruction: "You are a helpful assistant",
});
```

<Callout type="info" title="Environment Configuration Required">
  - **Gemini models** (default): Only need `GOOGLE_API_KEY` in your environment
  - **Other providers**: Must set both `LLM_MODEL` and the corresponding API key
  (`OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, etc.)
</Callout>

### Supported Model Names

| Provider          | Example Model Names                                    | Required API Key                    |
| ----------------- | ------------------------------------------------------ | ----------------------------------- |
| **Google Gemini** | `gemini-2.0-flash`, `gemini-2.0-pro`, `gemini-1.5-pro` | `GOOGLE_API_KEY` (default provider) |
| **OpenAI**        | `gpt-4o`, `gpt-4`, `gpt-3.5-turbo`                     | `OPENAI_API_KEY`                    |
| **Anthropic**     | `claude-3-5-sonnet-20241022`, `claude-3-opus`          | `ANTHROPIC_API_KEY`                 |
| **Groq**          | `llama-3.1-70b-versatile`, `mixtral-8x7b`              | `GROQ_API_KEY`                      |
| **Mistral**       | `mistral-large-latest`, `codestral-latest`             | `MISTRAL_API_KEY`                   |

## Option 2: Vercel AI SDK Integration

For more control and advanced features, use model instances from the [Vercel AI SDK](https://ai-sdk.dev/docs/introduction). This approach provides access to multiple providers with consistent APIs and advanced capabilities.

### Setup Requirements

**1. Install Provider Packages:**

```bash
# Install the providers you want to use
npm install @ai-sdk/openai      # For OpenAI models
npm install @ai-sdk/anthropic   # For Anthropic models
npm install @ai-sdk/google      # For Google models
npm install @ai-sdk/mistral     # For Mistral models
npm install @ai-sdk/groq        # For Groq models
```

**2. Configure API Keys:**

```bash
# .env file
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here
GROQ_API_KEY=your_groq_api_key_here
```

**3. Use Model Instances:**

```typescript
import { LlmAgent } from "@iqai/adk";
import { openai } from "@ai-sdk/openai";
import { anthropic } from "@ai-sdk/anthropic";
import { google } from "@ai-sdk/google";
import { mistral } from "@ai-sdk/mistral";
import { groq } from "@ai-sdk/groq";

// OpenAI models
const gpt4Agent = new LlmAgent({
  name: "gpt4_agent",
  model: openai("gpt-4o"),
  instruction: "You are a helpful assistant",
});

// Anthropic models
const claudeAgent = new LlmAgent({
  name: "claude_agent",
  model: anthropic("claude-3-5-sonnet-20241022"),
  instruction: "You are a helpful assistant",
});

// Google models via Vercel AI SDK
const geminiAgent = new LlmAgent({
  name: "gemini_agent",
  model: google("gemini-2.0-flash"),
  instruction: "You are a helpful assistant",
});

// Mistral models
const mistralAgent = new LlmAgent({
  name: "mistral_agent",
  model: mistral("mistral-large-latest"),
  instruction: "You are a helpful assistant",
});

// Groq models
const groqAgent = new LlmAgent({
  name: "groq_agent",
  model: groq("llama-3.1-70b-versatile"),
  instruction: "You are a helpful assistant",
});
```

### Supported Providers

<Cards>
  <Card
    title="🤖 OpenAI"
    description="GPT-4o, GPT-4, GPT-3.5, and latest ChatGPT models"
  />

{" "}

<Card
  title="🧠 Anthropic"
  description="Claude 3.5 Sonnet, Claude 3 Opus, and Haiku models"
/>

{" "}

<Card
  title="🔥 Mistral"
  description="Mistral Large, Codestral, and specialized models"
/>

{" "}

<Card
  title="⚡ Groq"
  description="Ultra-fast inference for Llama, Mixtral, and Gemma models"
/>

  <Card
    title="🌐 Many Others"
    description="Google, Perplexity, Cohere, and other providers"
  />
</Cards>

The Vercel AI SDK supports many more providers beyond what's shown here. Check the [official documentation](https://ai-sdk.dev/providers) for the complete list of supported providers and models.

<Callout type="info" title="Local & Open Source Models">
  Local and open source models (like Ollama, self-hosted models) are also
  supported through the Vercel AI SDK approach. Install the appropriate provider
  package (`@ai-sdk/ollama`, etc.) and configure as needed. Note that not all
  local models support function calling reliably.
</Callout>

## Which Option Should You Choose?

| Use Case                 | Recommended Option        | Why                                        |
| ------------------------ | ------------------------- | ------------------------------------------ |
| **Getting Started**      | Option 1 (Gemini default) | Simple setup, just need GOOGLE_API_KEY     |
| **Production Apps**      | Option 1 with env config  | Simple, reliable, fewer dependencies       |
| **Multi-Provider**       | Option 2 (Vercel AI SDK)  | Unified interface, consistent APIs         |
| **Advanced Features**    | Option 2 (Vercel AI SDK)  | Streaming, advanced config, type safety    |
| **Local/Private Models** | Option 2 (Vercel AI SDK)  | Only option that supports local deployment |

## Next Steps

<Cards>
  <Card
    title="🤖 Create Your First LLM Agent"
    description="Learn how to use models with LLM agents and get started building"
    href="/docs/framework/agents/llm-agents"
  />

{" "}

<Card
  title="🔧 Use Agent Builder"
  description="Rapidly create agents with the fluent API and model configuration"
  href="/docs/framework/agents/agent-builder"
/>

{" "}

<Card
  title="🛠️ Add Tools to Your Agents"
  description="Integrate tools with different model types for enhanced capabilities"
  href="/docs/framework/tools"
/>

  <Card
    title="👥 Build Multi-Agent Systems"
    description="Coordinate multiple agents with different models and specializations"
    href="/docs/framework/agents/multi-agents"
  />
</Cards>
